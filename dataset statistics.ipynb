{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the average sentences/tokens of stories, --> token = 117.8 , sent = 9\n",
    "#average length of questions,             -->tokens: all:23, YN:25 FB:14  FR:27  CO:25\n",
    "#the average number of options and       --> it is fixed, FB: [0, 6966, 16536]\n",
    "#correct options of each types of questions, \n",
    "#train\n",
    "#                                            FB: ['A', 'B', 'C', none] [11849 11767  8293  1668]\n",
    "#                                            FR:  [left right above below near  far  touching   DK] [4855 4970 5997 8634 1262  311  135   96]\n",
    "#                                            CO: [first, second, both, none] [5908 6077 9523  958]\n",
    "#                                            YN: [Y, N, DK] [12833  4587  6356]\n",
    "#test\n",
    "#                                            FB: ['A', 'B', 'C', none] [1786 1816 1361  338]\n",
    "#                                            FR:  [left right above below near  far  touching   DK] [ 619  593  872 1465   82   18   10    5]\n",
    "#                                            CO: [first, second, both, none] [ 871  847 1414  117]\n",
    "#                                            YN: [Y, N, DK] [1773  854  957]\n",
    "#percentage of DK questions of each type of questions, \n",
    "#train\n",
    "# FB: /23502   YN: /23776    FR:   /23055      CO:   /22466\n",
    "#test\n",
    "# FB: /3560   YN: /3584    FR:   / 3410     CO:   /3249\n",
    "\n",
    "#criterion for train/test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average sentences/tokens of stories: token = 117.8 , sent = 9\n",
    "# The  average length (tokens) of questions: all:23, YN:25, FB:14,  FR:27,  CO:25\n",
    "# The average number of options for each q-type:  Their length of all q-types are static (except FB that can have 2 or 3 options)  FR: 7, CO: 4 (always two options are given, the answer can be: the first one, the second one, both of them, None), YN: 2,  FB: 2.9 (In average) \n",
    "# The correct options of each types of questions: \n",
    "# For Train:\n",
    "# FR: Total = 23055 →   [left: 4855, right:4970 , above: 5997, below: 8634, near to: 1262,  far from:  311 ,  touching:135 ]\n",
    "# FB: Total = 23502 → ['A': 11849, 'B':11767 , 'C': 8293]\n",
    "# CO: Total = 22466 → [first option: 5908, second option: 6077, both:9523 , none: 958]\n",
    "# YN: Total = 23776 → [Yes: 12833, No: 4587 ]\n",
    "# For Test:\n",
    "# FR: Total = 3410  → [left: 619, right:593 , above: 872, below: 1465, near to: 82,  far from:  18 ,  touching:10 ]\n",
    "# FB: Total = 3560  → ['A': 1786, 'B':1816 , 'C': 1361]\n",
    "\n",
    "# CO: Total = 3249 → [first option: 871, second option: 847, both:1414 , none: 117]\n",
    "# YN: Total = 3584 → [Yes: 1773, No: 854 ]\n",
    "\n",
    "# The percentage of DK questions of each type of questions:\n",
    "# \tTrain:\n",
    "# DK: FR: 0.4%, YN: 26.73.\n",
    "# None: FB:7.09 % , CO: 4.2%,\n",
    "# \tTest:   \n",
    "# DK: FR: 0.1%, YN: 26.70.\n",
    "# None: FB:9.4 % , CO: 3.6%,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "with open('Dataset/train_24k.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples = random.sample(data['data'], 1000)\n",
    "  \n",
    "x = []\n",
    "for story in data_samples[:]:\n",
    "# for story in data['data']:\n",
    "    \n",
    "    story_txt = story['story'][0]\n",
    "    x.append(len(word_tokenize(story_txt)))\n",
    "#     print(word_tokenize(story_txt))\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "np.average(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.168975300400534"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# data_samples = random.sample(data['data'], 1000)\n",
    "  \n",
    "# print(len(data_samples))\n",
    "x = []\n",
    "# for story in data_samples[:]:\n",
    "for story in data['data']:\n",
    "    \n",
    "    story_txt = story['story'][0]\n",
    "    x.append(len(sent_tokenize(story_txt)))\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "np.average(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.010910294321736"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples = random.sample(data['data'], 1000)\n",
    "x = []\n",
    "\n",
    "# for story in data_samples[:]:\n",
    "for story in data['data']:\n",
    "    \n",
    "    for question in story['questions']:\n",
    "        \n",
    "#         q_type = question['q_type']\n",
    "        q_txt = question['question']\n",
    "        x.append(len(word_tokenize(q_txt)))\n",
    "#         question['q_type'], question['candidate_answers'], question['answer']\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "np.average(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.278420724650584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples = random.sample(data['data'], 1000)\n",
    "x = []\n",
    "\n",
    "# for story in data_samples[:]:\n",
    "for story in data['data']:\n",
    "    \n",
    "    for question in story['questions']:\n",
    "        \n",
    "#         q_type = question['q_type']\n",
    "        if question['q_type'] == 'CO':\n",
    "            q_txt = question['question']\n",
    "            x.append(len(word_tokenize(q_txt)))\n",
    "#         question['q_type'], question['candidate_answers'], question['answer']\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "np.average(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6966, 16536]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_samples = random.sample(data['data'], 1000)\n",
    "# x = []\n",
    "z = [0]*3\n",
    "\n",
    "# for story in data_samples[:]:\n",
    "for story in data['data']:\n",
    "    \n",
    "    for question in story['questions']:\n",
    "        \n",
    "#         q_type = question['q_type']\n",
    "        if question['q_type'] == 'FB':\n",
    "            z[len(question['candidate_answers'])-1] += 1\n",
    "#             q_txt = question['question']\n",
    "#         question['q_type'], question['candidate_answers'], question['answer']\n",
    "\n",
    "# x = np.array(x)\n",
    "\n",
    "# np.average(x)\n",
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
